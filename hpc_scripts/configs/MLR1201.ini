######################################################################
####################### Update this sections #########################
######################################################################
#
[slurm]
account = def-banire
mail_user = amine.m.remita@gmail.com

[main_settings]
job_name = MLR1201
cpus_per_task = 5
# gpu:1 |Â gpu:v100l:1 | cpu
#gres = gpu:1
gres = cpu
mem = 32000M
#mem = 190000M
#time = 23:30:00
time = 01:00:00
# /scratch
output_folder = /scratch/mremita/MLR_project/

[main_evals]
#
k_list = 9
#eval_types = CC
eval_types = FF
penalties = none, l2, l1 
#penalties = l1
#fragment_sizes = 250, 500
fragment_sizes = 500
sim_iterations = 1,10
#sim_iterations = 1,1
#
mutations = 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 5e-2, 1e-1, 2e-1
#mutations = 1e-2
indels = 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 5e-2, 1e-1, 2e-1
recombs = 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 5e-2, 1e-1, 2e-1
# in case of recombs set dual infection prob to
rep_dual_infection = 0.01
# in case of indels set the NB distri parameters
indel_model_nb = 0.4 1

######################################################################
########### The following will be updated automatically ##############
######################################################################
[job]
job_code = job

[io]
outdir = outdir

[simulation]
iterations = 10
# init_seq : [file, none]
# If none, a random nucleotide sequence will be generated
init_seq = none
init_seq_size = 5000
init_pop_size = 100
init_gen_count_fraction = 0.3
##
# Parameters related to class sizes
nb_classes = 10
class_pop_size = 50
class_pop_size_min = 5
class_pop_size_max = 100
# class_pop_size_std controls how
# simulated dataset is imbalanced
# class_pop_size will be used as mean
class_pop_size_std = 10
##
# Evolution related parameters
generation_count = 1000
fitness_freq = 0.5
rep_dual_infection = 0.
rep_recombination = 0.
mutation_rate = 0.
transition_bias = 2.0
# The 2 parameters of NB distr. for indel model
# seprated by a white space
indel_model_nb = None
# Probability of insertion and deletion events
indel_prob = 0.

[seq_rep]
k = 4
full_kmers = False
low_var_threshold = None
fragment_size = 500
fragment_count = 1
fragment_cov = 2
##
# Sampling dataset classes
# (before fragmentation if any)
class_size_min = 5
class_size_max = 100
class_size_mean = 50
# class_size_std controls the how
# sampling already-generated datasetis imbalanced
class_size_std = 0.

[evaluation] 
# CC, CF or FF 
eval_type = CC
test_size = 0.33
cv_folds = 5
# precision, recall, fscore or all
eval_metric = fscore
# micro, macro or weighted
avrg_metric = macro

[classifier]
module = pytorch_mlr
tol = 1e-5
lambda = 1
l1_ratio = 0.5
solver = sgd
max_iter = 5000
### for pytorch implementation
learning_rate = 0.0001
n_iter_no_change = 500
device = cuda
##
# these penalities will be evaluated
penalty = none, l2, l1

[settings]
n_main_jobs = 1
n_cv_jobs = ${evaluation:cv_folds}
verbose = 1
load_data = True
save_data = True
load_models = True
save_models = True
load_results = True
save_results = True
save_final_results = False
plot_results = False
plot_results_only = False
random_state = 75
