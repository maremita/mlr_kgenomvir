# THIS CONFIG FILE SHOULD BE RUN WITH 
# mlr_eval_sim_imbalanced_dataset.py

[job]
job_code = IMBDATA

[io]
#seq_file = ../data/viruses/HBV01/data.fa
outdir = ../data/output/pt/mlr_sim_imb/sim/

[simulation]
iterations = 1
# init_seq : [file, none]
# If file, uncomment seq_file line in [io] section
# If none, a random nucleotide sequence will be generated
init_seq = none
init_seq_size = 1000
init_pop_size = 100
init_gen_count_fraction = 0.3
##
# Parameters related to class sizes
nb_classes = 10
class_pop_size = 25
class_pop_size_min = 5
class_pop_size_max = 200
# ... main evaluation parameter ........
class_pop_size_std = 0, 5, 10, 50, 100
# ......................................
generation_count = 1000
fitness_freq = 0.5
rep_dual_infection = 0.05
rep_recombination = 0.001
mutation_rate = 0.03
transition_bias = 2.0
# The 2 parameters of NB distr. for indel model
# seprated by a white space
indel_model_nb = 0.4 1
# Probability of insertion and deletion events
indel_prob = 0.001

[seq_rep]
k = 5
full_kmers = False
low_var_threshold = 0.01
fragment_size = 1000
fragment_count = 1000
fragment_cov = 2
##
# Sampling dataset classes
# (before fragmentation if any)
class_size_min = 5
class_size_max = 200
class_size_mean = 50
# class_size_std controls the how
# sampling already-generated datasetis imbalanced
class_size_std = 0

[evaluation] 
# CC, CF or FF 
eval_type = CC
test_size = 0.33
cv_folds = 2
# precision, recall, fscore or all
eval_metric = fscore
# micro, macro or weighted
avrg_metric = macro

[classifier]
module = pytorch_mlr
tol = 1e-5
lambda = 1
l1_ratio = 0.5
solver = sgd
max_iter = 1000
### for pytorch implementation
learning_rate = 0.0001
n_iter_no_change = 100
device = cpu
##
# these penalities will be evaluated
penalty = l1, l2

[settings]
n_main_jobs = 2
n_cv_jobs = ${evaluation:cv_folds}
verbose = 1
load_data = False
save_data = True
load_models = False
save_models = True
load_results = False
save_results = True
save_final_results = True
plot_results = True
random_state = 42
